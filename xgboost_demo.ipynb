{"cells":[{"cell_type":"code","execution_count":null,"id":"786d74dc-08cb-45e2-82ad-4aa265c68c1c","metadata":{"id":"786d74dc-08cb-45e2-82ad-4aa265c68c1c"},"outputs":[],"source":["# import sys\n","# !{sys.executable} -m pip install xgboost"]},{"cell_type":"code","execution_count":null,"id":"3648b3b7-b41b-4f9f-8ecf-e991c3677c59","metadata":{"id":"3648b3b7-b41b-4f9f-8ecf-e991c3677c59"},"outputs":[],"source":["import xgboost as xgb\n","\n","#Other imports\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"id":"e4e0c69b-2e13-4441-8baf-9e484e033170","metadata":{"id":"e4e0c69b-2e13-4441-8baf-9e484e033170","outputId":"69e4a95e-ef6f-4190-d30d-c9622525c33e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>carat</th>\n","      <th>cut</th>\n","      <th>color</th>\n","      <th>clarity</th>\n","      <th>depth</th>\n","      <th>table</th>\n","      <th>price</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.23</td>\n","      <td>Ideal</td>\n","      <td>E</td>\n","      <td>SI2</td>\n","      <td>61.5</td>\n","      <td>55.0</td>\n","      <td>326</td>\n","      <td>3.95</td>\n","      <td>3.98</td>\n","      <td>2.43</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.21</td>\n","      <td>Premium</td>\n","      <td>E</td>\n","      <td>SI1</td>\n","      <td>59.8</td>\n","      <td>61.0</td>\n","      <td>326</td>\n","      <td>3.89</td>\n","      <td>3.84</td>\n","      <td>2.31</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.23</td>\n","      <td>Good</td>\n","      <td>E</td>\n","      <td>VS1</td>\n","      <td>56.9</td>\n","      <td>65.0</td>\n","      <td>327</td>\n","      <td>4.05</td>\n","      <td>4.07</td>\n","      <td>2.31</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.29</td>\n","      <td>Premium</td>\n","      <td>I</td>\n","      <td>VS2</td>\n","      <td>62.4</td>\n","      <td>58.0</td>\n","      <td>334</td>\n","      <td>4.20</td>\n","      <td>4.23</td>\n","      <td>2.63</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.31</td>\n","      <td>Good</td>\n","      <td>J</td>\n","      <td>SI2</td>\n","      <td>63.3</td>\n","      <td>58.0</td>\n","      <td>335</td>\n","      <td>4.34</td>\n","      <td>4.35</td>\n","      <td>2.75</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   carat      cut color clarity  depth  table  price     x     y     z\n","0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n","1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n","2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n","3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n","4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["## Data import\n","diamonds = sns.load_dataset(\"diamonds\")\n","diamonds.head()"]},{"cell_type":"code","execution_count":null,"id":"addb90f0-f178-4307-a077-0583a6a273d1","metadata":{"id":"addb90f0-f178-4307-a077-0583a6a273d1","outputId":"fb0d1c13-1e95-41d6-e759-7e8306db82a1"},"outputs":[{"data":{"text/plain":["(53940, 10)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["diamonds.shape"]},{"cell_type":"code","execution_count":null,"id":"3e2243d8-846b-49d3-9c6e-33582240a7d3","metadata":{"id":"3e2243d8-846b-49d3-9c6e-33582240a7d3","outputId":"548c09c1-76ca-43cb-a244-f0f5e5b99c1e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>carat</th>\n","      <th>depth</th>\n","      <th>table</th>\n","      <th>price</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>53940.000000</td>\n","      <td>53940.000000</td>\n","      <td>53940.000000</td>\n","      <td>53940.000000</td>\n","      <td>53940.000000</td>\n","      <td>53940.000000</td>\n","      <td>53940.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.797940</td>\n","      <td>61.749405</td>\n","      <td>57.457184</td>\n","      <td>3932.799722</td>\n","      <td>5.731157</td>\n","      <td>5.734526</td>\n","      <td>3.538734</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.474011</td>\n","      <td>1.432621</td>\n","      <td>2.234491</td>\n","      <td>3989.439738</td>\n","      <td>1.121761</td>\n","      <td>1.142135</td>\n","      <td>0.705699</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.200000</td>\n","      <td>43.000000</td>\n","      <td>43.000000</td>\n","      <td>326.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.400000</td>\n","      <td>61.000000</td>\n","      <td>56.000000</td>\n","      <td>950.000000</td>\n","      <td>4.710000</td>\n","      <td>4.720000</td>\n","      <td>2.910000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.700000</td>\n","      <td>61.800000</td>\n","      <td>57.000000</td>\n","      <td>2401.000000</td>\n","      <td>5.700000</td>\n","      <td>5.710000</td>\n","      <td>3.530000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.040000</td>\n","      <td>62.500000</td>\n","      <td>59.000000</td>\n","      <td>5324.250000</td>\n","      <td>6.540000</td>\n","      <td>6.540000</td>\n","      <td>4.040000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>5.010000</td>\n","      <td>79.000000</td>\n","      <td>95.000000</td>\n","      <td>18823.000000</td>\n","      <td>10.740000</td>\n","      <td>58.900000</td>\n","      <td>31.800000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              carat         depth         table         price             x  \\\n","count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n","mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n","std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n","min        0.200000     43.000000     43.000000    326.000000      0.000000   \n","25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n","50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n","75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n","max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n","\n","                  y             z  \n","count  53940.000000  53940.000000  \n","mean       5.734526      3.538734  \n","std        1.142135      0.705699  \n","min        0.000000      0.000000  \n","25%        4.720000      2.910000  \n","50%        5.710000      3.530000  \n","75%        6.540000      4.040000  \n","max       58.900000     31.800000  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["diamonds.describe()"]},{"cell_type":"markdown","id":"5ce791af-05b9-4485-8c24-d3d6b5fb3db3","metadata":{"id":"5ce791af-05b9-4485-8c24-d3d6b5fb3db3"},"source":["## Objective\n","\n","Predict diamond price from their physical characteristics."]},{"cell_type":"code","execution_count":null,"id":"2b78b976-f0d1-4e55-bdad-3f1bfdbc693e","metadata":{"id":"2b78b976-f0d1-4e55-bdad-3f1bfdbc693e"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Extract feature and target arrays\n","X, y = diamonds.drop('price', axis=1), diamonds[['price']]"]},{"cell_type":"markdown","id":"d430bc8a-1112-4f30-a060-2984bea28294","metadata":{"id":"d430bc8a-1112-4f30-a060-2984bea28294"},"source":["## Building an XGBoost DMatrix\n","\n","XGBoost has the ability to deal with categorical variables internally, rather than requiring the user to cast each as one-hot encoded values. But, these input categorical features need to be type `category` in Pandas."]},{"cell_type":"code","execution_count":null,"id":"e1207fae-0221-43c5-9e6f-58d09356d30b","metadata":{"id":"e1207fae-0221-43c5-9e6f-58d09356d30b","outputId":"a76dad4b-52b4-4030-c6e6-090c593d2acf"},"outputs":[{"data":{"text/plain":["['cut', 'color', 'clarity']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#Extract text features\n","cats = X.select_dtypes(exclude=np.number).columns.tolist()\n","cats"]},{"cell_type":"code","execution_count":null,"id":"024f5cfa-831e-4511-88e4-2b19a6674310","metadata":{"id":"024f5cfa-831e-4511-88e4-2b19a6674310","outputId":"438982a7-d333-44d9-b974-ae7876f5dbce"},"outputs":[{"data":{"text/plain":["carat       float64\n","cut        category\n","color      category\n","clarity    category\n","depth       float64\n","table       float64\n","x           float64\n","y           float64\n","z           float64\n","dtype: object"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["for col in cats:\n","    X[col] = X[col].astype('category')\n","X.dtypes #See category types"]},{"cell_type":"code","execution_count":null,"id":"58db5886-bb92-492a-8c37-6df2ae2e3878","metadata":{"id":"58db5886-bb92-492a-8c37-6df2ae2e3878"},"outputs":[],"source":["X, y = diamonds.drop('price', axis=1), diamonds[['price']]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1973)"]},{"cell_type":"markdown","id":"5231d549-0d49-45cc-b1a8-1d69884d2f48","metadata":{"id":"5231d549-0d49-45cc-b1a8-1d69884d2f48"},"source":["The `DMatrix` type is the method for storing data in XGBoost that is fast, & highly memory efficient."]},{"cell_type":"code","execution_count":null,"id":"2c07f065-e6c7-42e2-a483-a7a70463d05a","metadata":{"id":"2c07f065-e6c7-42e2-a483-a7a70463d05a"},"outputs":[],"source":["dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n","dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"]},{"cell_type":"markdown","id":"7b72af1a-3a4c-40ca-b025-be94e04e2c2d","metadata":{"id":"7b72af1a-3a4c-40ca-b025-be94e04e2c2d"},"source":["## Loss Functions & Metrics in XGBoost\n","\n","A _loss function_ is used by a machine learning model to minimize the _differences_ between actual (\"ground truth\") values and model predictions. Separately, a metric is chosen  by the ML engineer to measure the _similarity_ between ground truth and model predictions. Metrics are used after training to evaluate overall performance (e.g., accuracy, recall, precision).\n","\n","The loss function is specified in a dictionary as the `\"objective\"` as follows:"]},{"cell_type":"code","execution_count":null,"id":"f5cbf8ea-186d-43c5-99d6-694c24c95c58","metadata":{"id":"f5cbf8ea-186d-43c5-99d6-694c24c95c58"},"outputs":[],"source":["# Define hyperparameters\n","\n","params = {\"objective\": \"reg:squarederror\", \"tree_method\": 'hist'}#\"gpu_hist\"}"]},{"cell_type":"markdown","id":"8e30169f-0026-4d2b-9af5-f53a22413f8f","metadata":{"id":"8e30169f-0026-4d2b-9af5-f53a22413f8f"},"source":["Inside this initial `params`, we are also setting `tree_method` to `gpu_hist`, which enables GPU acceleration. If you don't have a GPU, you can omit the parameter or set it to `hist`.\n","\n","## Boosting Rounds\n","\n","XGBoost's time to shine. The `num_boost_round` parameter sets the number of _boosting rounds_. For the given loss function (RMSE in this example), XGB minimizes the loss in small incremental rounds. In practice, this parameter is found through hyperparameter tuning. But, here we will set it to 100."]},{"cell_type":"code","execution_count":null,"id":"0f75256b-8593-40a1-8693-2a7eec69d6cf","metadata":{"id":"0f75256b-8593-40a1-8693-2a7eec69d6cf"},"outputs":[],"source":["n = 100\n","model = xgb.train(\n","    params=params\n","    , dtrain=dtrain_reg\n","    , num_boost_round=n\n",")"]},{"cell_type":"markdown","id":"264c81b7-e64d-49fa-8c1b-6c137b58b5ef","metadata":{"id":"264c81b7-e64d-49fa-8c1b-6c137b58b5ef"},"source":["## Evaluation\n","\n","XGBoost modes has a `.predict()` method that we will use to compare to actual diamond price values and calculation an overall RMSE."]},{"cell_type":"code","execution_count":null,"id":"bd5e6c1d-c07e-436b-b218-ef68a36e6b6f","metadata":{"id":"bd5e6c1d-c07e-436b-b218-ef68a36e6b6f","outputId":"55111178-69e4-40df-bbd8-4aa6fea8118d"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE of the base model: 538.167\n"]}],"source":["from sklearn.metrics import mean_squared_error\n","\n","preds = model.predict(dtest_reg)\n","rmse = mean_squared_error(y_test, preds, squared=False)\n","print(f\"RMSE of the base model: {rmse:.3f}\")"]},{"cell_type":"markdown","id":"fed9b97c-29a1-4df0-80fc-65e2e8230882","metadata":{"id":"fed9b97c-29a1-4df0-80fc-65e2e8230882"},"source":["This performance value is a good baseline. We can see the minimization of error accross boosting rounds by passing the validation set `dtest_reg` to the model as well. Because boosting round will often number in the thousands, we can use the `verbose_eval` parameter to control how often updates are printed:"]},{"cell_type":"code","execution_count":null,"id":"375faf91-e9b2-4c4d-95de-1a9ca3924c50","metadata":{"id":"375faf91-e9b2-4c4d-95de-1a9ca3924c50","outputId":"eccbe638-9762-4487-f802-7784142085e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0]\ttrain-rmse:3977.45382\tvalidation-rmse:3964.19581\n","[10]\ttrain-rmse:555.33206\tvalidation-rmse:591.31313\n","[20]\ttrain-rmse:492.49286\tvalidation-rmse:549.47014\n","[30]\ttrain-rmse:465.39701\tvalidation-rmse:542.16912\n","[40]\ttrain-rmse:447.86009\tvalidation-rmse:540.88764\n","[50]\ttrain-rmse:431.70047\tvalidation-rmse:538.63653\n","[60]\ttrain-rmse:421.17886\tvalidation-rmse:538.36693\n","[70]\ttrain-rmse:403.50555\tvalidation-rmse:538.51618\n","[80]\ttrain-rmse:394.27771\tvalidation-rmse:537.13333\n","[90]\ttrain-rmse:383.51864\tvalidation-rmse:537.37270\n","[99]\ttrain-rmse:374.76291\tvalidation-rmse:538.16748\n"]}],"source":["evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n","model = xgb.train(\n","    params=params\n","    , dtrain=dtrain_reg\n","    , num_boost_round=n\n","    , evals=evals\n","    , verbose_eval=10\n",")"]},{"cell_type":"markdown","id":"d8ca8f07-93b0-4a29-8baa-a04cfdaa1ef2","metadata":{"id":"d8ca8f07-93b0-4a29-8baa-a04cfdaa1ef2"},"source":["\n","## Early Stopping\n","\n","Notice above that the loss does not inherently decrease as the number of boosting rounds increases. At a larger scale, let's see what happens at 5000 boosting rounds (verbosity at 500)."]},{"cell_type":"code","execution_count":null,"id":"5feaa826-0f86-4644-8b99-c466644cd71c","metadata":{"id":"5feaa826-0f86-4644-8b99-c466644cd71c","outputId":"b481c6a7-6bd8-430a-ddd4-e9e22a5918c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0]\ttrain-rmse:3977.45382\tvalidation-rmse:3964.19581\n","[500]\ttrain-rmse:200.58807\tvalidation-rmse:552.49024\n","[1000]\ttrain-rmse:127.96630\tvalidation-rmse:558.97226\n","[1500]\ttrain-rmse:89.94796\tvalidation-rmse:562.83895\n","[2000]\ttrain-rmse:67.12858\tvalidation-rmse:565.19271\n","[2500]\ttrain-rmse:53.08825\tvalidation-rmse:566.63096\n","[3000]\ttrain-rmse:43.08917\tvalidation-rmse:567.41885\n","[3500]\ttrain-rmse:36.61729\tvalidation-rmse:568.02380\n","[4000]\ttrain-rmse:32.02086\tvalidation-rmse:568.44478\n","[4500]\ttrain-rmse:28.70827\tvalidation-rmse:568.78321\n","[4999]\ttrain-rmse:26.39354\tvalidation-rmse:568.95641\n"]}],"source":["model = xgb.train(\n","    params=params\n","    , dtrain=dtrain_reg\n","    , num_boost_round=5000\n","    , evals=evals\n","    , verbose_eval=500\n",")"]},{"cell_type":"markdown","id":"7ce2b567-b5ba-4482-aafa-0d224b3ce057","metadata":{"id":"7ce2b567-b5ba-4482-aafa-0d224b3ce057"},"source":["The training RMSE continues to decline. However, the validation RMSE levels off and appears to be slightly worse than some of the earliest boosting rounds. The model is memorizing the training data rather than generalizing for future observations, which ultimately reduce its performance. Instead we want a model in the _golden middle_. We can find this using XGBoost's early stopping criterea, `early_stopping_rounds = x`, where the model will hald training if the validation performance does not improve for `x` rounds. Setting this parameter allows us to choose as many boosting rounds as we like, such as `num_boost_round=10000`."]},{"cell_type":"code","execution_count":null,"id":"b8c90773-efa4-477c-b233-6d914c70073f","metadata":{"id":"b8c90773-efa4-477c-b233-6d914c70073f","outputId":"f11fef79-6ffe-4ddd-a5a2-4d7f78e327e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0]\ttrain-rmse:3977.45382\tvalidation-rmse:3964.19581\n","[132]\ttrain-rmse:346.56655\tvalidation-rmse:542.94340\n"]}],"source":["model = xgb.train(\n","    params=params\n","    , dtrain=dtrain_reg\n","    , num_boost_round=10000\n","    , evals=evals\n","    , verbose_eval=500\n","    , early_stopping_rounds=50\n",")"]},{"cell_type":"markdown","id":"3ae59091-4388-498b-8bee-e69eb1d839da","metadata":{"id":"3ae59091-4388-498b-8bee-e69eb1d839da"},"source":["The XGB model stopped itself at an early round as the performance in the validation set plateaued."]},{"cell_type":"markdown","id":"47113533-2c61-4ea5-bb3a-419b12271a41","metadata":{"id":"47113533-2c61-4ea5-bb3a-419b12271a41"},"source":["## XGBoost Cross-Validation\n","\n","Using a single test-set to validate the results of a machine learning model is problematic, as the model is able to implicitly memorize the test-set in its iterative optimization steps. This is because the hyperparameter optimization will optimize to the specific validation test-set, which may not generalize as well to new test-sets.\n","\n","The solution to this issue is $k$-fold cross-validation with the `xgb.cv()` function instead of `.train()`:"]},{"cell_type":"code","execution_count":null,"id":"2bda8c98-95a9-4ed7-bfa9-ef281b225ded","metadata":{"id":"2bda8c98-95a9-4ed7-bfa9-ef281b225ded","outputId":"8d336421-b644-47f7-ac33-184053470b94"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0]\ttrain-rmse:3977.43576+10.07020\ttest-rmse:3978.85810+40.09560\n","[63]\ttrain-rmse:402.66435+3.15904\ttest-rmse:558.10036+9.32226\n"]}],"source":["results = xgb.cv(\n","    params=params\n","    , dtrain=dtrain_reg\n","    , num_boost_round=1000\n","    , verbose_eval=500\n","    , early_stopping_rounds=20\n","    , nfold=5\n",")"]},{"cell_type":"markdown","id":"c8d403fb-0b50-4ab5-b538-8de2707a3fb6","metadata":{"id":"c8d403fb-0b50-4ab5-b538-8de2707a3fb6"},"source":["Instead of passing a test and training set in `evals` in the `.train()` function, we allow the `cv()` function to pseudorandomly create folds with the `nfold` parameter. Instead of a single model object, the `cv()` function returns a list of results that are the mean of cross-validated model results for _every_ boosting round:"]},{"cell_type":"code","execution_count":null,"id":"766cc2a8-72a3-41e0-ab35-b7841c0f4376","metadata":{"id":"766cc2a8-72a3-41e0-ab35-b7841c0f4376","outputId":"62317927-34d4-4857-c22a-5c44132c49b7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train-rmse-mean</th>\n","      <th>train-rmse-std</th>\n","      <th>test-rmse-mean</th>\n","      <th>test-rmse-std</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3977.435758</td>\n","      <td>10.070199</td>\n","      <td>3978.858100</td>\n","      <td>40.095596</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2843.757606</td>\n","      <td>7.006502</td>\n","      <td>2847.097944</td>\n","      <td>31.381355</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2057.786913</td>\n","      <td>5.627692</td>\n","      <td>2064.569714</td>\n","      <td>25.364942</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1518.225476</td>\n","      <td>4.319844</td>\n","      <td>1528.032156</td>\n","      <td>22.361016</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1154.995565</td>\n","      <td>4.154201</td>\n","      <td>1169.602765</td>\n","      <td>17.903318</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n","0      3977.435758       10.070199     3978.858100      40.095596\n","1      2843.757606        7.006502     2847.097944      31.381355\n","2      2057.786913        5.627692     2064.569714      25.364942\n","3      1518.225476        4.319844     1528.032156      22.361016\n","4      1154.995565        4.154201     1169.602765      17.903318"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["results.head()"]},{"cell_type":"markdown","id":"6e57efb5-4c88-4815-9bac-22b25b944dca","metadata":{"id":"6e57efb5-4c88-4815-9bac-22b25b944dca"},"source":["This means that a new model will need to be trained given the results of CV after the minimum RMSE is found:"]},{"cell_type":"code","execution_count":null,"id":"71de3887-dc12-4993-a4de-a3db244d8b03","metadata":{"id":"71de3887-dc12-4993-a4de-a3db244d8b03","outputId":"97b71d50-c1ae-4512-a192-2ce3e0700bb9"},"outputs":[{"data":{"text/plain":["555.694556080344"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["best_rmse = results['test-rmse-mean'].min()\n","\n","best_rmse"]},{"cell_type":"markdown","id":"c2fa8c58-7389-4601-b753-d5d273201e53","metadata":{"id":"c2fa8c58-7389-4601-b753-d5d273201e53"},"source":["## XGBoost Classification\n","\n","The 2 most popular classification objectives are as follows:\n","\n","- `binary:logistic`: binary classification\n","- `multi:softprob`: multi-class classification\n","\n","The technical details of performing these 2 classification methods are nearly identical. For this problem, we will switch up the target variable to be the `'cut'` quality and use price as well as the remaining variables as regressors."]},{"cell_type":"code","execution_count":null,"id":"a9ea3fc1-d8bd-4786-8beb-add1a62c91b3","metadata":{"id":"a9ea3fc1-d8bd-4786-8beb-add1a62c91b3"},"outputs":[],"source":["from sklearn.preprocessing import OrdinalEncoder\n","\n","X, y = diamonds.drop(\"cut\", axis=1), diamonds[['cut']]\n","\n","#Encode y to be numeric\n","y_encoded = OrdinalEncoder().fit_transform(y) #\"Fair\" -> \"Good\" -> \"Very Good\" -> \"Premium\" -> \"Ideal\"\n","\n","#Extract text features\n","cats = X.select_dtypes(exclude=np.number).columns.tolist()\n","\n","#Convert to pd.categorical\n","for col in cats:\n","    X[col] = X[col].astype('category')\n","\n","#Recreate training/test splits w/ y_encoded\n","X_train, X_test, y_encoded_train, y_encoded_test = train_test_split(X, y_encoded, random_state=1, stratify=y_encoded)\n","\n","#Create classification matrices\n","dtrain_clf = xgb.DMatrix(X_train, y_encoded_train, enable_categorical=True)\n","dtest_clf = xgb.DMatrix(X_test, y_encoded_test, enable_categorical=True)"]},{"cell_type":"markdown","id":"43c9f4da-8a92-47d8-b249-aab7a9d71f53","metadata":{"id":"43c9f4da-8a92-47d8-b249-aab7a9d71f53"},"source":["Note the `enable_categorical` to account for the categorical `y` target. Below, this requires us to specify the number of classes, `\"num_class\"`."]},{"cell_type":"code","execution_count":null,"id":"860c966c-f5fa-4d81-b1ee-7386dfc73dc1","metadata":{"id":"860c966c-f5fa-4d81-b1ee-7386dfc73dc1"},"outputs":[],"source":["params = {\n","    \"objective\": \"multi:softprob\"\n","    , \"tree_method\": \"hist\"\n","    , \"num_class\": 5\n","}\n","\n","results = xgb.cv(\n","    params, dtrain_clf\n","    , num_boost_round=1000\n","    , nfold=5\n","    , metrics=[\"mlogloss\", \"auc\", \"merror\"]\n",")"]},{"cell_type":"markdown","id":"68d139b7-f054-4288-b402-b261fbb2ea23","metadata":{"id":"68d139b7-f054-4288-b402-b261fbb2ea23"},"source":["During cross-validation, we are asking XGBoost to monitor 3 different classification metrics: Log-loss, AUC, and whatever the hell `\"merror\"` is (mean error?)."]},{"cell_type":"code","execution_count":null,"id":"40230108-383b-4069-9bf3-2cea7b44ee81","metadata":{"id":"40230108-383b-4069-9bf3-2cea7b44ee81","outputId":"233f608e-1484-4d54-c675-39638c982ffd"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train-mlogloss-mean</th>\n","      <th>train-mlogloss-std</th>\n","      <th>train-auc-mean</th>\n","      <th>train-auc-std</th>\n","      <th>train-merror-mean</th>\n","      <th>train-merror-std</th>\n","      <th>test-mlogloss-mean</th>\n","      <th>test-mlogloss-std</th>\n","      <th>test-auc-mean</th>\n","      <th>test-auc-std</th>\n","      <th>test-merror-mean</th>\n","      <th>test-merror-std</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>179</th>\n","      <td>0.262976</td>\n","      <td>0.000751</td>\n","      <td>0.989071</td>\n","      <td>0.000088</td>\n","      <td>0.082647</td>\n","      <td>0.000726</td>\n","      <td>0.534053</td>\n","      <td>0.004886</td>\n","      <td>0.940314</td>\n","      <td>0.00081</td>\n","      <td>0.200396</td>\n","      <td>0.003197</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     train-mlogloss-mean  train-mlogloss-std  train-auc-mean  train-auc-std  \\\n","179             0.262976            0.000751        0.989071       0.000088   \n","\n","     train-merror-mean  train-merror-std  test-mlogloss-mean  \\\n","179           0.082647          0.000726            0.534053   \n","\n","     test-mlogloss-std  test-auc-mean  test-auc-std  test-merror-mean  \\\n","179           0.004886       0.940314       0.00081          0.200396   \n","\n","     test-merror-std  \n","179         0.003197  "]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["max_auc = results['test-auc-mean'].max()\n","results[results['test-auc-mean'] == max_auc]"]},{"cell_type":"markdown","id":"09a65e8f-7b30-44c6-8b5a-0874b40b0454","metadata":{"id":"09a65e8f-7b30-44c6-8b5a-0874b40b0454"},"source":["## XGBoost SKLearn API\n","\n","XGBoost offers `XGBClassifier` and `XGBRegressor` classes that easily integrate into a Sci-Kit Learn ecosystem, at a loss of some functionality."]},{"cell_type":"code","execution_count":null,"id":"1dc06e42-395c-4c19-9aeb-563b75bfa425","metadata":{"id":"1dc06e42-395c-4c19-9aeb-563b75bfa425","outputId":"dad297dd-27d1-4265-fd66-f7e9fd94a006"},"outputs":[{"name":"stdout","output_type":"stream","text":["XGB Classifier fitted!\n"]}],"source":["#Train a model using the sci-kit learn API\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=100\n","    , objective='binary:logistic'\n","    , tree_method='hist'\n","    , eta=0.1\n","    , max_depth=3\n","    , enable_categorical=True\n",")\n","xgb_classifier.fit(X_train, y=y_encoded_train)\n","print(\"XGB Classifier fitted!\")"]},{"cell_type":"markdown","id":"b361d6b4-cb32-42d2-acfd-54238f91198c","metadata":{"id":"b361d6b4-cb32-42d2-acfd-54238f91198c"},"source":["This model may be used to `predict` diamond quality outcomes:"]},{"cell_type":"code","execution_count":null,"id":"a2570219-613b-4b0d-b7e6-c64ce201d6f4","metadata":{"id":"a2570219-613b-4b0d-b7e6-c64ce201d6f4","outputId":"94bfa607-4bee-499d-9870-e3906448d4c7"},"outputs":[{"data":{"text/plain":["0.8615289372688394"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["#RMSE\n","errors = (xgb_classifier.predict(X_test) - y_encoded_test.flatten())\n","np.sqrt((errors**2).mean())"]},{"cell_type":"markdown","id":"c5ddf204-cbc7-4005-9975-cf71c94ad1d1","metadata":{"id":"c5ddf204-cbc7-4005-9975-cf71c94ad1d1"},"source":["And, the native XGBoost API model may be extracted with the `.get_booster()` method."]},{"cell_type":"code","execution_count":null,"id":"8ec37aa2-11ab-4086-ba88-28ff0a8088ff","metadata":{"id":"8ec37aa2-11ab-4086-ba88-28ff0a8088ff"},"outputs":[],"source":["model = xgb_classifier.get_booster()"]},{"cell_type":"markdown","id":"e869b997-da36-43da-a38d-a0436c0e3f1b","metadata":{"id":"e869b997-da36-43da-a38d-a0436c0e3f1b"},"source":["## References\n","\n","- XGBoost Parameters Page: [https://xgboost.readthedocs.io/en/stable/parameter.html](https://xgboost.readthedocs.io/en/stable/parameter.html)\n","- DataCamp Tutorial: [https://www.datacamp.com/tutorial/xgboost-in-python](https://www.datacamp.com/tutorial/xgboost-in-python)"]},{"cell_type":"code","execution_count":null,"id":"f7337ca1-f721-4f24-a02d-56760bf8854d","metadata":{"id":"f7337ca1-f721-4f24-a02d-56760bf8854d"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}